{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./img/UNIBET.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ./PProcess0.ipynb\n",
    "# driver = webdriver.Chrome(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üîé PROCESSING MATCHES ---\n",
      "‚úÖ fra.1 (France): Found 16 matches\n",
      "‚úÖ fra.2 (France): Found 8 matches\n",
      "\n",
      "üèÅ SUCCESS: dfGames ready with 24 total matches.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# --- Helper: Strip Accents ---\n",
    "def strip_accents(text):\n",
    "    if not isinstance(text, str): return text\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "# --- 1. Use your existing df_mapping logic ---\n",
    "# (Assumes df_mapping is already created from the code you provided)\n",
    "\n",
    "# --- 2. Fetch Data ---\n",
    "url = \"https://www.unibet.fr/zones/v3/sportnode/markets.json?nodeId=2243762&filter=R%C3%A9sultat&marketname=R%C3%A9sultat%20du%20match\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        json_data = response.json()\n",
    "        raw_events = []\n",
    "        \n",
    "        # Access the API structure\n",
    "        markets = json_data.get(\"marketsByType\", [])\n",
    "        if markets:\n",
    "            for day, d in enumerate(markets[0].get(\"days\", [])):\n",
    "                for e in d.get(\"events\", []):\n",
    "                    raw_events.append({\n",
    "                        \"Day\": day,\n",
    "                        \"Match\": e.get(\"eventName\"),\n",
    "                        \"EventId\": e.get(\"eventId\"),\n",
    "                        \"competitionName\": e.get(\"competitionName\"),\n",
    "                        \"clean_comp\": strip_accents(e.get(\"competitionName\", \"\"))\n",
    "                    })\n",
    "        \n",
    "        dfRaw = pd.DataFrame(raw_events)\n",
    "\n",
    "        # --- 3. Refined Matching using df_mapping ---\n",
    "        all_matched_dfs = []\n",
    "\n",
    "        print(\"--- üîé PROCESSING MATCHES ---\")\n",
    "        # Iterate directly through your mapping DataFrame\n",
    "        for _, row in df_mapping.iterrows():\n",
    "            pattern = row['Regex_Pattern']\n",
    "            code = row['Comp_Code']\n",
    "            country = row['Country']\n",
    "            \n",
    "            if pattern == \"No Pattern Defined\":\n",
    "                continue\n",
    "            \n",
    "            # Use search instead of match for better flexibility with API names\n",
    "            regex = re.compile(pattern, re.IGNORECASE)\n",
    "            mask = dfRaw[\"clean_comp\"].apply(lambda x: bool(regex.search(str(x))))\n",
    "            \n",
    "            if mask.any():\n",
    "                # Extract the matches and tag them with the mapping info\n",
    "                temp_df = dfRaw[mask].copy()\n",
    "                temp_df['Comp_Code'] = code\n",
    "                temp_df['Country'] = country\n",
    "                all_matched_dfs.append(temp_df)\n",
    "                print(f\"‚úÖ {code} ({country}): Found {len(temp_df)} matches\")\n",
    "\n",
    "        # --- 4. Final Data Assembly ---\n",
    "        if all_matched_dfs:\n",
    "            dfGames = pd.concat(all_matched_dfs, ignore_index=True)\n",
    "            \n",
    "            # Split Match into Home and Away\n",
    "            df_split = dfGames['Match'].str.split(' - ', n=1, expand=True)\n",
    "            dfGames['Home'] = df_split[0]\n",
    "            dfGames['Away'] = df_split[1]\n",
    "            \n",
    "            # Select final columns\n",
    "            dfGames = dfGames[['Day', 'Comp_Code', 'Country', 'Home', 'Away', 'EventId', 'competitionName']]\n",
    "            \n",
    "            # Optional: Remove duplicates if a game matches two different patterns\n",
    "            dfGames = dfGames.drop_duplicates(subset=['EventId', 'Comp_Code'])\n",
    "            \n",
    "            print(\"\\nüèÅ SUCCESS: dfGames ready with\", len(dfGames), \"total matches.\")\n",
    "        else:\n",
    "            print(\"\\nüö® No matches found for the mapped competitions.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"üö® SCRIPT ERROR: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.DataFrame(row_data1)\n",
    "# a = a['competitionName'].unique()\n",
    "# b = dfGames['competitionName'].unique()\n",
    "# list(set(a) ^ set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:43<00:00,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully extracted 1765 odds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm._instances.clear()\n",
    "import pandas as pd\n",
    "\n",
    "# --- Initialization ---\n",
    "row_data0 = []\n",
    "session = requests.Session()\n",
    "# Headers to look like a real browser\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Referer\": \"https://www.unibet.fr/sport/football\"\n",
    "})\n",
    "\n",
    "# --- The Loop ---\n",
    "# Using a slightly slower pace to avoid 503 errors\n",
    "for i, idgame in enumerate(tqdm(dfGames[\"EventId\"])):\n",
    "    idgame_str = str(idgame)\n",
    "    url = f\"https://www.unibet.fr/zones/event.json?eventId={idgame_str}\"\n",
    "    \n",
    "    # 1. ANTI-BOT DELAY: Random pause between 1 to 2 seconds\n",
    "    time.sleep(random.uniform(1.0, 2.0))\n",
    "    \n",
    "    # 2. CHUNKING: Take a longer break every 15 matches to reset server tracking\n",
    "    if i % 15 == 0 and i > 0:\n",
    "        time.sleep(5)\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, timeout=15)\n",
    "        \n",
    "        # 3. RETRY LOGIC: If 503 occurs, wait and try one last time\n",
    "        if response.status_code == 503:\n",
    "            time.sleep(10) \n",
    "            response = session.get(url, timeout=20)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            json_data = response.json()\n",
    "            \n",
    "            # Extract basic info safely\n",
    "            header = json_data.get(\"eventHeader\", {})\n",
    "            competitionName = header.get('competitionName', 'Unknown')\n",
    "            \n",
    "            start_date = header.get('eventStartDate')\n",
    "            DateTime = datetime.datetime.fromtimestamp(start_date / 1000).strftime('%Y-%m-%d %H:%M:%S') if start_date else \"N/A\"\n",
    "\n",
    "            # Locate the markets\n",
    "            market_classes = json_data.get('marketClassList', [])\n",
    "            if not market_classes:\n",
    "                continue\n",
    "\n",
    "            # # --- NEW: Print all marketNames found in this match ---\n",
    "            # found_markets = [m.get('marketName') for m in market_classes]\n",
    "            # print(f\"\\nüîç Markets found for {idgame_str}: {found_markets}\")\n",
    "            # # ------------------------------------------------------\n",
    "            \n",
    "            # Identify Home/Away from the main match result market\n",
    "            try:\n",
    "                duel = market_classes[0]['marketList'][0]['selections']\n",
    "                home = strip_accents(duel[0]['name'])\n",
    "                away = strip_accents(duel[2]['name'])\n",
    "            except (IndexError, KeyError):\n",
    "                home, away = \"Unknown\", \"Unknown\"\n",
    "\n",
    "            # 4. PARSE SPECIFIC MARKETS\n",
    "            # target_markets = [\n",
    "            #     'Total de buts', \n",
    "            #     'Combo chance double & Total de buts',\n",
    "            #     'But pour les 2 √©quipes',\n",
    "            #     'R√©sultat du match',\n",
    "            #     'Chance double',\n",
    "            #     'Combo chance double & les 2 √©quipes marquent'\n",
    "            # ]\n",
    "            target_markets = [\n",
    "                'R√©sultat du match',\n",
    "                'Double chance',\n",
    "                'Total de buts',\n",
    "                'But pour les 2 √©quipes',\n",
    "                'Combo r√©sultat du match & Total de buts',\n",
    "                'Combo r√©sultat du match & Les 2 √©quipes marquent',\n",
    "                'Combo double chance & Total de buts',\n",
    "                'Combo double chance & les 2 √©quipes marquent',\n",
    "                # 'Score exact',\n",
    "                # 'Mi-temps / Fin de match',\n",
    "                # 'Buteur',\n",
    "                # 'Nombre total de tirs cadr√©s'\n",
    "            ]\n",
    "\n",
    "            for m in market_classes:\n",
    "                if m.get('marketName') in target_markets:\n",
    "                    for m_list in m.get('marketList', []):\n",
    "                        for j in m_list.get('selections', []):\n",
    "                            try:\n",
    "                                # Safe Odd Calculation\n",
    "                                up = float(j['currentPriceUp'])\n",
    "                                down = float(j['currentPriceDown'])\n",
    "                                odd = round(1 + (up / down), 2)\n",
    "                                \n",
    "                                row_data0.append({\n",
    "                                    \"IdGame\": idgame_str,\n",
    "                                    \"DateTime\": DateTime,\n",
    "                                    \"Competition\": competitionName,\n",
    "                                    \"Home\": home,\n",
    "                                    \"Away\": away,\n",
    "                                    \"Bet\": j.get('name'),\n",
    "                                    \"Odd\": odd\n",
    "                                })\n",
    "                            except (ZeroDivisionError, KeyError, TypeError):\n",
    "                                continue \n",
    "        else:\n",
    "            print(f\"Skipping {idgame_str}: Received Status {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Connection Error for {idgame_str}: {e}\")\n",
    "        continue\n",
    "\n",
    "# --- 5. Final Output ---\n",
    "dfOdds = pd.DataFrame(row_data0)\n",
    "if not dfOdds.empty:\n",
    "    print(f\"‚úÖ Successfully extracted {len(dfOdds)} odds.\")\n",
    "    # display(dfOdds.head(15))\n",
    "else:\n",
    "    print(\"‚ùå No odds were extracted. Check if market names match the API.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success: 25 matches processed.\n",
      "üö© Unmapped bets: <ArrowStringArray>\n",
      "[       'HFoot/D',   'HFoot/StadeA',         'H&M1,5',         'H&P1,5',\n",
      "         'D&M1,5',         'D&P1,5',         'A&M1,5',         'A&P1,5',\n",
      "         'H&M2,5',         'H&P2,5',\n",
      " ...\n",
      "     'D/A29&M4,5',     'D/A29&P4,5', 'ParisFc/D&M1,5', 'ParisFc/D&P1,5',\n",
      " 'ParisFc/D&M2,5', 'ParisFc/D&P2,5', 'ParisFc/D&M3,5', 'ParisFc/D&P3,5',\n",
      " 'ParisFc/D&M4,5', 'ParisFc/D&P4,5']\n",
      "Length: 208, dtype: str\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Bet</th>\n",
       "      <th>IdGame</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>Competition</th>\n",
       "      <th>A</th>\n",
       "      <th>D</th>\n",
       "      <th>H</th>\n",
       "      <th>H/D</th>\n",
       "      <th>D/A</th>\n",
       "      <th>...</th>\n",
       "      <th>M2,5</th>\n",
       "      <th>M3,5</th>\n",
       "      <th>M4,5</th>\n",
       "      <th>M5,5</th>\n",
       "      <th>P0,5</th>\n",
       "      <th>P1,5</th>\n",
       "      <th>P2,5</th>\n",
       "      <th>P3,5</th>\n",
       "      <th>P4,5</th>\n",
       "      <th>P5,5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3368697_1</td>\n",
       "      <td>2026-02-14 14:00:00</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>Reims</td>\n",
       "      <td>Ligue 2 BKT¬Æ</td>\n",
       "      <td>1.79</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.82</td>\n",
       "      <td>6.10</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3368847_1</td>\n",
       "      <td>2026-02-14 14:00:00</td>\n",
       "      <td>Montpellier</td>\n",
       "      <td>Le Mans</td>\n",
       "      <td>Ligue 2 BKT¬Æ</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.28</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.46</td>\n",
       "      <td>...</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>3.32</td>\n",
       "      <td>8.50</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3364905_1</td>\n",
       "      <td>2026-02-14 17:00:00</td>\n",
       "      <td>Marseille</td>\n",
       "      <td>Strasbourg</td>\n",
       "      <td>Ligue 1 McDonald's¬Æ</td>\n",
       "      <td>3.92</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>...</td>\n",
       "      <td>2.04</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.54</td>\n",
       "      <td>2.30</td>\n",
       "      <td>4.05</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3364903_1</td>\n",
       "      <td>2026-02-14 19:00:00</td>\n",
       "      <td>Lille</td>\n",
       "      <td>Brest</td>\n",
       "      <td>Ligue 1 McDonald's¬Æ</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.75</td>\n",
       "      <td>5.40</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3368851_1</td>\n",
       "      <td>2026-02-14 20:00:00</td>\n",
       "      <td>Guingamp</td>\n",
       "      <td>Saint-Etienne</td>\n",
       "      <td>Ligue 2 BKT¬Æ</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>...</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.72</td>\n",
       "      <td>5.15</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Bet     IdGame             DateTime         Home           Away  \\\n",
       "7    3368697_1  2026-02-14 14:00:00     Grenoble          Reims   \n",
       "8    3368847_1  2026-02-14 14:00:00  Montpellier        Le Mans   \n",
       "2    3364905_1  2026-02-14 17:00:00    Marseille     Strasbourg   \n",
       "1    3364903_1  2026-02-14 19:00:00        Lille          Brest   \n",
       "9    3368851_1  2026-02-14 20:00:00     Guingamp  Saint-Etienne   \n",
       "\n",
       "Bet          Competition     A     D     H   H/D   D/A  ...  M2,5  M3,5  M4,5  \\\n",
       "7           Ligue 2 BKT¬Æ  1.79  3.45  4.35   NaN  1.17  ...  1.66  1.24  1.07   \n",
       "8           Ligue 2 BKT¬Æ  3.15  3.08  2.28  1.29  1.46  ...  1.49  1.16  1.04   \n",
       "2    Ligue 1 McDonald's¬Æ  3.92  4.05  1.86  1.22  1.85  ...  2.04  1.42  1.15   \n",
       "1    Ligue 1 McDonald's¬Æ  6.00  4.30  1.56  1.11   NaN  ...  1.78  1.29  1.09   \n",
       "9           Ligue 2 BKT¬Æ  2.75  3.55  2.36  1.39  1.47  ...  1.85  1.33  1.11   \n",
       "\n",
       "Bet  M5,5  P0,5  P1,5  P2,5  P3,5  P4,5  P5,5  \n",
       "7    1.01  1.03  1.24  1.79  2.82  6.10  15.2  \n",
       "8    1.01  1.05  1.33  2.04  3.32  8.50  23.0  \n",
       "2    1.04  1.02  1.16  1.54  2.30  4.05   8.5  \n",
       "1    1.02  1.03  1.22  1.73  2.75  5.40  12.5  \n",
       "9    1.03  1.03  1.22  1.72  2.72  5.15  12.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "\n",
    "# --- 1. DEFINE ALL DICTIONARIES ---\n",
    "# Paste the full content of your MatchTeamNames here to ensure they are in memory\n",
    "DictTeam = {\n",
    "    \"VfB Stuttgart\": \"Stuttgart\", \"FC Augsburg\": \"Augsbourg\", \"Karlsruher SC\": \"Karlsruhe\",\n",
    "    \"SC Paderborn 07\": \"Paderborn\", \"1. FC Heidenheim\": \"Heidenheim\", \"SSV Jahn Regensburg\": \"Jahn Regensburg\",\n",
    "    \"FC St. Pauli\": \"St. Pauli\", \"VfL Bochum\": \"Bochum\", \"Bayern Munich\": \"Bayern Munich\",\n",
    "    \"RB Leipzig\": \"RB Leipzig\", \"Hertha Berlin\": \"Hertha BSC\", \"M'gladbach\": \"Borussia M'Gladbach\",\n",
    "    \"Bayer Leverkusen\": \"Bayer Leverkusen\", \"VfL Wolfsburg\": \"Wolfsbourg\", \"Hambourg\": \"Hamburger SV\",\n",
    "    \"Eintracht Frankfurt\": \"Eintracht Francfort\", \"1. FC Union Berlin\": \"Union Berlin\",\n",
    "    \"Schalke 04\": \"Schalke 04\", \"Borussia Dortmund\": \"Dortmund\", \"Werder Bremen\": \"Werder Breme\",\n",
    "    \"Paris Saint-Germain \": \"Paris SG\", \"AS Monaco\": \"Monaco\", \"AC Milan\": \"AC Milan\",\n",
    "    \"Internazionale\": \"Inter Milan\", \"Juventus Turin\": \"Juventus\", \"AS Rome\": \"AS Roma\"\n",
    "    # ... (Include all other teams from your list here)\n",
    "}\n",
    "\n",
    "# Auto-generate the bidirectional dictionary\n",
    "Dict_teams = {}\n",
    "for key, value in DictTeam.items():\n",
    "    if len(key) <= len(value):\n",
    "        Dict_teams[value] = key\n",
    "    else:\n",
    "        Dict_teams[key] = value\n",
    "\n",
    "special_dict0 = {\"1 FC Nuremberg\": \"Nurnberg\"}\n",
    "\n",
    "special_dict = {\n",
    "    \"FK Autriche Wien\": \"Austria Vienne\", \"FC Seville\": \"Sevilla\", \"Palerme FC\": \"Palerme\",\n",
    "    \"Venezia FC\": \"Venezia\", \"FC Nuremberg\": \"Nurnberg\", \"Atalanta BC\": \"Atalanta\",\n",
    "    \"Girona FC\": \"Gerone\", \"Watford FC\": \"Watford\", \"Toulouse FC\": \"Toulouse\"\n",
    "    # ... (Include other special mappings)\n",
    "}\n",
    "\n",
    "# --- 2. INITIALIZE DATAFRAME ---\n",
    "OddGames = pd.DataFrame(row_data0)\n",
    "\n",
    "# Normalize text (Remove accents and ensure strings)\n",
    "for col in ['Bet', 'Home', 'Away']:\n",
    "    OddGames[col] = OddGames[col].apply(lambda x: unidecode(str(x)) if x and str(x) != 'nan' else x)\n",
    "\n",
    "# --- 3. APPLY TEAM MAPPINGS & MARKERS (H/A) ---\n",
    "# Apply special dicts first\n",
    "for d in [special_dict0, special_dict]:\n",
    "    OddGames[\"Bet\"] = OddGames[\"Bet\"].replace(d, regex=True)\n",
    "    OddGames[\"Away\"] = OddGames[\"Away\"].replace(d, regex=True)\n",
    "    OddGames[\"Home\"] = OddGames[\"Home\"].replace(d, regex=True)\n",
    "\n",
    "inverted_dict = {v: k for k, v in Dict_teams.items()}\n",
    "\n",
    "# Function to replace specific team names with 'H' or 'A' in the Bet string\n",
    "def replace_team_markers(row):\n",
    "    res = str(row[\"Bet\"])\n",
    "    h_re = re.escape(str(row[\"Home\"]))\n",
    "    a_re = re.escape(str(row[\"Away\"]))\n",
    "    res = re.sub(a_re, 'A', res)\n",
    "    res = re.sub(h_re, 'H', res)\n",
    "    return res\n",
    "\n",
    "# Apply dictionaries and then convert names to H/A markers\n",
    "for d in [inverted_dict, Dict_teams]:\n",
    "    OddGames[\"Away\"] = OddGames[\"Away\"].replace(d)\n",
    "    OddGames[\"Home\"] = OddGames[\"Home\"].replace(d)\n",
    "    OddGames[\"Bet\"] = OddGames[\"Bet\"].replace(d)\n",
    "\n",
    "OddGames[\"Bet\"] = OddGames.apply(replace_team_markers, axis=1)\n",
    "\n",
    "# --- 4. STANDARDIZE BET NAMES ---\n",
    "replacements = {\n",
    "    r'Moins de ': 'M', r'Plus de ': 'P', r' ou ': '/',\n",
    "    r'under ': 'M', r'over ': 'P', r' Or ': '/', r' or ': '/',\n",
    "    r'Match nul': 'D', r'match nul': 'D', r'Match Nul': 'D',\n",
    "    r'Draw': 'D', r'draw': 'D', r'Egalite': 'D',\n",
    "    r'Oui': 'LDEM', r'Non': 'LDEMP', r'Yes': 'LDEM', r'No': 'LDEMP',\n",
    "    r'\\s+': '' # Remove all whitespace\n",
    "}\n",
    "\n",
    "for old, new in replacements.items():\n",
    "    OddGames[\"Bet\"] = OddGames[\"Bet\"].str.replace(old, new, regex=True)\n",
    "\n",
    "# Convert dots to commas for your specific requirements\n",
    "OddGames['Bet'] = OddGames['Bet'].str.replace('.', ',', regex=False)\n",
    "\n",
    "# --- 5. PIVOT TABLE ---\n",
    "Unibet_Wide = OddGames.pivot_table(\n",
    "    index=['IdGame', 'DateTime', 'Home', 'Away', 'Competition'],\n",
    "    columns='Bet', values='Odd', aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# --- 6. FINAL COLUMN ALIGNMENT ---\n",
    "Cols = [\n",
    "    'IdGame', 'DateTime', 'Home', 'Away', 'Competition', \n",
    "    'A', 'D', 'H', 'H/D', 'D/A', 'H/A', \n",
    "    'H/D&M1,5', 'H/D&M2,5', 'H/D&M3,5', 'H/D&M4,5',\n",
    "    'H/D&P1,5', 'H/D&P2,5', 'H/D&P3,5', 'H/D&P4,5', \n",
    "    'D/A&M1,5', 'D/A&M2,5', 'D/A&M3,5', 'D/A&M4,5',\n",
    "    'D/A&P1,5', 'D/A&P2,5', 'D/A&P3,5', 'D/A&P4,5', \n",
    "    'H/A&M1,5', 'H/A&M2,5', 'H/A&M3,5', 'H/A&M4,5',\n",
    "    'H/A&P1,5', 'H/A&P2,5', 'H/A&P3,5', 'H/A&P4,5', \n",
    "    'LDEM', 'LDEMP', \n",
    "    'H/D&LDEM', 'H/D&LDEMP', 'D/A&LDEM', 'D/A&LDEMP', 'H/A&LDEM', 'H/A&LDEMP', \n",
    "    'M0,5', 'M1,5', 'M2,5', 'M3,5', 'M4,5', 'M5,5',\n",
    "    'P0,5', 'P1,5', 'P2,5', 'P3,5', 'P4,5', 'P5,5'\n",
    "]\n",
    "\n",
    "# Ensure all standard columns exist, filling missing ones with NaN\n",
    "for col in Cols:\n",
    "    if col not in Unibet_Wide.columns:\n",
    "        Unibet_Wide[col] = np.nan\n",
    "\n",
    "Unibet = Unibet_Wide[Cols].sort_values(by='DateTime')\n",
    "\n",
    "# Final Verification\n",
    "mask = ~OddGames['Bet'].isin(Cols)\n",
    "print(f\"‚úÖ Success: {len(Unibet)} matches processed.\")\n",
    "if len(OddGames[mask]['Bet'].unique()) > 0:\n",
    "    print(f\"üö© Unmapped bets: {OddGames[mask]['Bet'].unique()}\")\n",
    "\n",
    "# display(Unibet.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No new matches found. CSV is already up to date.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Save UNIBET odds ---\n",
    "file_path = \"Odds_Match.csv\"\n",
    "\n",
    "# 1. Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    csv_df = pd.read_csv(file_path)\n",
    "    # Ensure IdGame is treated as a string for comparison\n",
    "    csv_df['IdGame'] = csv_df['IdGame'].astype(str)\n",
    "else:\n",
    "    # Create an empty DataFrame with the correct columns if file is missing\n",
    "    csv_df = pd.DataFrame(columns=Unibet.columns)\n",
    "\n",
    "# 2. Identify matches NOT already in the CSV\n",
    "# We convert IdGame to string to ensure the comparison works perfectly\n",
    "unibet_ids = Unibet['IdGame'].astype(str)\n",
    "csv_ids = csv_df['IdGame'].unique()\n",
    "\n",
    "is_new_match = ~unibet_ids.isin(csv_ids)\n",
    "\n",
    "# 3. Combine and Save\n",
    "if is_new_match.any():\n",
    "    # Filter only the new matches\n",
    "    new_data = Unibet[is_new_match]\n",
    "    \n",
    "    # Concatenate\n",
    "    updated_csv = pd.concat([csv_df, new_data], ignore_index=True)\n",
    "    \n",
    "    # Standardize dates and sort\n",
    "    updated_csv['DateTime'] = pd.to_datetime(updated_csv['DateTime'])\n",
    "    updated_csv = updated_csv.sort_values(by='DateTime')\n",
    "    \n",
    "    # Save to CSV\n",
    "    updated_csv.to_csv(file_path, index=False, encoding='utf-8')\n",
    "    print(f\"‚úÖ Added {len(new_data)} new matches to {file_path}\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No new matches found. CSV is already up to date.\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
